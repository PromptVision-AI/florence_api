# Florence API Service

A FastAPI-based service that leverages the Florence-2 model for advanced image and text processing. This project provides a containerized API service that can be easily deployed using Docker.

## ğŸš€ Features

- FastAPI-based REST API
- Florence-2 model integration
- GPU acceleration support
- Containerized deployment
- Environment variable configuration

## ğŸ“‹ Prerequisites

- Docker
- NVIDIA GPU with CUDA support
- NVIDIA Container Toolkit installed

## ğŸ› ï¸ Project Structure

```
florence_api/
â”œâ”€â”€ app/                    # Application code
â”œâ”€â”€ model/                  # Florence model files
â”œâ”€â”€ docker/                 # Docker configuration
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ docker-compose.yml
â”œâ”€â”€ main.py                # FastAPI application entry point
â”œâ”€â”€ requirements.txt       # Python dependencies
â””â”€â”€ .env                   # Environment variables
```

## ğŸ”§ Configuration

Create a `.env` file in the root directory with the following variables:
```env
API_HOST=0.0.0.0
API_PORT=8000
MODEL_PATH=/app/model
```

## ğŸš€ Running with Docker

1. **Build the Docker image**
   ```bash
   cd docker
   docker compose build --no-cache
   ```

2. **Start the service**
   ```bash
   docker compose up
   ```

   The API will be available at `http://localhost:8000`

3. **Stop the service**
   ```bash
   docker compose down
   ```

## ğŸ” API Documentation

Once the service is running, you can access:
- API documentation: `http://localhost:8000/docs`
- Alternative documentation: `http://localhost:8000/redoc`

## ğŸ›Ÿ Troubleshooting

### CUDA Version Issues
Make sure your NVIDIA driver supports the CUDA version specified in the Dockerfile. You can check your supported CUDA version with:
```bash
nvidia-smi
```

### GPU Access Issues
Ensure the NVIDIA Container Toolkit is properly installed:
```bash
nvidia-container-cli info
```

## ğŸ“ License

[Your License Here]

## ğŸ¤ Contributing

[Your Contributing Guidelines Here] 